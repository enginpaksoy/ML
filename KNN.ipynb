{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM+zmKp4Vh3NNmQN0S+3aV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enginpaksoy/ML/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pkHFHHyKrivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k):\n",
        "        \"\"\"\n",
        "        Initialize the KNN class with k neighbors.\n",
        "        Args:\n",
        "            k (int): Number of nearest neighbors.\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        if(k % 2 != 1):\n",
        "            raise ValueError(\"k must be an odd number\")\n",
        "\n",
        "    def fit(self, training_features, training_labels):\n",
        "        \"\"\"\n",
        "        Store the training data.\n",
        "        Args:\n",
        "            training_features (numpy array): Features of the training data.\n",
        "            training_labels (numpy array): Labels of the training data.\n",
        "        \"\"\"\n",
        "        self.training_features = training_features\n",
        "        self.training_labels = training_labels\n",
        "\n",
        "    def predict(self, test_features):\n",
        "        \"\"\"\n",
        "        Predict the labels for the test data.\n",
        "        Args:\n",
        "            test_features (numpy array): Features of the test data.\n",
        "        Returns:\n",
        "            numpy array: Predicted labels for the test data.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for test_instance in test_features:\n",
        "            distances = []\n",
        "            # Calculate distance from the test instance to all training instances\n",
        "            for training_instance in self.training_features:\n",
        "                distances.append(self.euclidean_distance(test_instance, training_instance))\n",
        "\n",
        "            # Find the k nearest neighbors\n",
        "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
        "            # records the indices with the lowest distance between them\n",
        "\n",
        "            nearest_labels = [self.training_labels[i] for i in nearest_neighbors]\n",
        "            # nearest_neighbors contains indices of the nearest neighbors\n",
        "            # Create a list of labels for these nearest neighbors by looking up the indices in self.training_labels\n",
        "\n",
        "            # Determine the most common label (voting)\n",
        "            predicted_label = max(set(nearest_labels), key=nearest_labels.count)\n",
        "            predictions.append(predicted_label)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def train_test_split(self, data, test_size=0.3):\n",
        "        \"\"\"\n",
        "        Split the data into training and test sets.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "            test_size (float): Size of the test set.\n",
        "        Returns:\n",
        "            tuple: Training and test sets.\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]  # Gets the number of samples in the data array.\n",
        "        num_test_samples = int(num_samples * test_size)  # Determines the size of the test set.\n",
        "        indices = np.random.permutation(num_samples)  # Creates an array of length num_samples and randomizes the elements of this array.\n",
        "        test_indices = indices[:num_test_samples]  # Takes the first n(length num_samples) indices for the test set.\n",
        "        train_indices = indices[num_test_samples:]  # Takes the remaining indices for the training set.\n",
        "        self.test_indices = test_indices\n",
        "        self.train_indices = train_indices\n",
        "        return data[train_indices], data[test_indices]  # Returns the training and test sets.\n",
        "\n",
        "    def euclidean_distance(self, instance1, instance2):\n",
        "        \"\"\"\n",
        "        Calculate the Euclidean distance between two instances.\n",
        "        Args:\n",
        "            instance1 (numpy array): The first instance.\n",
        "            instance2 (numpy array): The second instance.\n",
        "        Returns:\n",
        "            float: The Euclidean distance between the two instances.\n",
        "        \"\"\"\n",
        "        instance1_new = np.array(instance1[:-1])\n",
        "        instance2_new = np.array(instance2[:-1])\n",
        "        # The code creates new arrays from instance1 and instance2, excluding their last elements.\n",
        "\n",
        "        return np.sqrt(np.sum((instance1_new - instance2_new) ** 2))\n"
      ],
      "metadata": {
        "id": "HOwsZFalr8n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/iris.csv', sep=',', skiprows=0)\n",
        "data_array = data.to_numpy()\n",
        "\n",
        "# Create a KNN model with k=5 neighbors\n",
        "knn = KNN(k=5)\n",
        "\n",
        "# Seperating training data and testing data\n",
        "# 30% of the data is reserved for testing, 70% is reserved for training\n",
        "train_set, test_set = knn.train_test_split(data_array, test_size=0.3)\n",
        "\n",
        "# Separate features and labels\n",
        "# [:, :-1]  # All rows, all columns except the last\n",
        "# [:, -1]   # All rows, only the last column\n",
        "train_features, train_labels = train_set[:, :-1], train_set[:, -1]\n",
        "test_features, test_labels = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "# Train the model\n",
        "knn.fit(train_features, train_labels)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "predictions = knn.predict(test_features)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = np.mean(predictions == test_labels)\n",
        "# If the value is equal it gives 1, if not it gives 0. and creates an array from this data and takes the average of this array\n",
        "\n",
        "print(f'# Accuracy: {accuracy:.2f}', end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for training\n",
        "print(\"# Train Indices: #\", train_features.shape[0])\n",
        "print(np.sort(knn.train_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for testing\n",
        "print(\"# Test Indices: #\", test_features.shape[0])\n",
        "print(np.sort(knn.test_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Different predictions from the real ones in the test data\n",
        "print(\"# Different predictions from the real ones in the test data: \", end=\"\\n\")\n",
        "for i in range(test_features.shape[0]):\n",
        "    if(test_labels[i] != predictions[i]):\n",
        "        print(f'Indices: {knn.test_indices[i]}, Test Labels: {test_labels[i]}, Predictions: {predictions[i]}', end = \"\\n\")"
      ],
      "metadata": {
        "id": "6HRo7jQNtxfW",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e9fc0b-4760-472c-f05b-dbd260b6b208"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Accuracy: 0.93\n",
            "\n",
            "# Train Indices: # 105\n",
            "[  0   1   3   4   6   7   8  10  11  12  16  17  18  19  21  22  25  26\n",
            "  27  28  29  30  31  32  33  37  38  39  42  43  46  47  48  49  50  51\n",
            "  52  53  54  60  61  62  64  65  66  67  68  69  70  72  75  76  77  78\n",
            "  79  81  82  83  84  87  88  89  90  92  94  95  96  97  98 100 101 102\n",
            " 103 105 106 108 109 111 112 114 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 130 131 132 135 136 138 141 142 144 146 147 148 149]\n",
            "\n",
            "# Test Indices: # 45\n",
            "[  2   5   9  13  14  15  20  23  24  34  35  36  40  41  44  45  55  56\n",
            "  57  58  59  63  71  73  74  80  85  86  91  93  99 104 107 110 113 115\n",
            " 128 129 133 134 137 139 140 143 145]\n",
            "\n",
            "# Different predictions from the real ones in the test data: \n",
            "Indices: 73, Test Labels: Iris-versicolor, Predictions: Iris-virginica\n",
            "Indices: 91, Test Labels: Iris-versicolor, Predictions: Iris-virginica\n",
            "Indices: 63, Test Labels: Iris-versicolor, Predictions: Iris-virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knnn = {}\n",
        "predictions = {}\n",
        "accuracy = {}\n",
        "\n",
        "for i in range(1, 151, 2):\n",
        "    knnn[i] = KNN(k=i)\n",
        "    knnn[i].fit(train_features, train_labels)\n",
        "    predictions[i] = knnn[i].predict(test_features)\n",
        "    accuracy[i] = np.mean(predictions[i] == test_labels)\n",
        "    print(f'# Accuracy for k = {i}: {accuracy[i]:.2f}')"
      ],
      "metadata": {
        "id": "9f03Dy73fdOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758219ff-7a6a-47ac-fc56-776141b2b2cb"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Accuracy for k = 1: 0.93\n",
            "# Accuracy for k = 3: 0.91\n",
            "# Accuracy for k = 5: 0.93\n",
            "# Accuracy for k = 7: 0.93\n",
            "# Accuracy for k = 9: 0.93\n",
            "# Accuracy for k = 11: 0.96\n",
            "# Accuracy for k = 13: 0.93\n",
            "# Accuracy for k = 15: 0.93\n",
            "# Accuracy for k = 17: 0.91\n",
            "# Accuracy for k = 19: 0.91\n",
            "# Accuracy for k = 21: 0.89\n",
            "# Accuracy for k = 23: 0.89\n",
            "# Accuracy for k = 25: 0.89\n",
            "# Accuracy for k = 27: 0.89\n",
            "# Accuracy for k = 29: 0.87\n",
            "# Accuracy for k = 31: 0.87\n",
            "# Accuracy for k = 33: 0.84\n",
            "# Accuracy for k = 35: 0.82\n",
            "# Accuracy for k = 37: 0.82\n",
            "# Accuracy for k = 39: 0.82\n",
            "# Accuracy for k = 41: 0.82\n",
            "# Accuracy for k = 43: 0.82\n",
            "# Accuracy for k = 45: 0.82\n",
            "# Accuracy for k = 47: 0.82\n",
            "# Accuracy for k = 49: 0.82\n",
            "# Accuracy for k = 51: 0.82\n",
            "# Accuracy for k = 53: 0.82\n",
            "# Accuracy for k = 55: 0.82\n",
            "# Accuracy for k = 57: 0.84\n",
            "# Accuracy for k = 59: 0.80\n",
            "# Accuracy for k = 61: 0.80\n",
            "# Accuracy for k = 63: 0.76\n",
            "# Accuracy for k = 65: 0.60\n",
            "# Accuracy for k = 67: 0.60\n",
            "# Accuracy for k = 69: 0.60\n",
            "# Accuracy for k = 71: 0.56\n",
            "# Accuracy for k = 73: 0.36\n",
            "# Accuracy for k = 75: 0.24\n",
            "# Accuracy for k = 77: 0.24\n",
            "# Accuracy for k = 79: 0.24\n",
            "# Accuracy for k = 81: 0.24\n",
            "# Accuracy for k = 83: 0.24\n",
            "# Accuracy for k = 85: 0.24\n",
            "# Accuracy for k = 87: 0.24\n",
            "# Accuracy for k = 89: 0.24\n",
            "# Accuracy for k = 91: 0.24\n",
            "# Accuracy for k = 93: 0.24\n",
            "# Accuracy for k = 95: 0.24\n",
            "# Accuracy for k = 97: 0.24\n",
            "# Accuracy for k = 99: 0.24\n",
            "# Accuracy for k = 101: 0.24\n",
            "# Accuracy for k = 103: 0.24\n",
            "# Accuracy for k = 105: 0.24\n",
            "# Accuracy for k = 107: 0.24\n",
            "# Accuracy for k = 109: 0.24\n",
            "# Accuracy for k = 111: 0.24\n",
            "# Accuracy for k = 113: 0.24\n",
            "# Accuracy for k = 115: 0.24\n",
            "# Accuracy for k = 117: 0.24\n",
            "# Accuracy for k = 119: 0.24\n",
            "# Accuracy for k = 121: 0.24\n",
            "# Accuracy for k = 123: 0.24\n",
            "# Accuracy for k = 125: 0.24\n",
            "# Accuracy for k = 127: 0.24\n",
            "# Accuracy for k = 129: 0.24\n",
            "# Accuracy for k = 131: 0.24\n",
            "# Accuracy for k = 133: 0.24\n",
            "# Accuracy for k = 135: 0.24\n",
            "# Accuracy for k = 137: 0.24\n",
            "# Accuracy for k = 139: 0.24\n",
            "# Accuracy for k = 141: 0.24\n",
            "# Accuracy for k = 143: 0.24\n",
            "# Accuracy for k = 145: 0.24\n",
            "# Accuracy for k = 147: 0.24\n",
            "# Accuracy for k = 149: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aFtvRoSP61IL"
      }
    }
  ]
}