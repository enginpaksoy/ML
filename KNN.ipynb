{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1e+P7QWu3zxIPlDELCrn4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enginpaksoy/ML/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pkHFHHyKrivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k):\n",
        "        \"\"\"\n",
        "        Initialize the KNN class with k neighbors.\n",
        "        Args:\n",
        "            k (int): Number of nearest neighbors.\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        if(k % 2 != 1):\n",
        "            raise ValueError(\"k must be an odd number\")\n",
        "\n",
        "    def fit(self, training_features, training_labels):\n",
        "        \"\"\"\n",
        "        Store the training data.\n",
        "        Args:\n",
        "            training_features (numpy array): Features of the training data.\n",
        "            training_labels (numpy array): Labels of the training data.\n",
        "        \"\"\"\n",
        "        self.training_features = training_features\n",
        "        self.training_labels = training_labels\n",
        "\n",
        "    def predict(self, test_features):\n",
        "        \"\"\"\n",
        "        Predict the labels for the test data.\n",
        "        Args:\n",
        "            test_features (numpy array): Features of the test data.\n",
        "        Returns:\n",
        "            numpy array: Predicted labels for the test data.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for test_instance in test_features:\n",
        "            distances = []\n",
        "            # Calculate distance from the test instance to all training instances\n",
        "            for training_instance in self.training_features:\n",
        "                distances.append(self.euclidean_distance(test_instance, training_instance))\n",
        "\n",
        "            # Find the k nearest neighbors\n",
        "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
        "            # records the indices with the lowest distance between them\n",
        "\n",
        "            nearest_labels = [self.training_labels[i] for i in nearest_neighbors]\n",
        "            # nearest_neighbors contains indices of the nearest neighbors\n",
        "            # Create a list of labels for these nearest neighbors by looking up the indices in self.training_labels\n",
        "\n",
        "            # Determine the most common label (voting)\n",
        "            predicted_label = max(set(nearest_labels), key=nearest_labels.count)\n",
        "            predictions.append(predicted_label)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def train_test_split(self, data, test_size=0.3):\n",
        "        \"\"\"\n",
        "        Split the data into training and test sets.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "            test_size (float): Size of the test set.\n",
        "        Returns:\n",
        "            tuple: Training and test sets.\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]  # Gets the number of samples in the data array.\n",
        "        num_test_samples = int(num_samples * test_size)  # Determines the size of the test set.\n",
        "        indices = np.random.permutation(num_samples)  # Creates an array of length num_samples and randomizes the elements of this array.\n",
        "        test_indices = indices[:num_test_samples]  # Takes the first n(length num_samples) indices for the test set.\n",
        "        train_indices = indices[num_test_samples:]  # Takes the remaining indices for the training set.\n",
        "        self.test_indices = test_indices\n",
        "        self.train_indices = train_indices\n",
        "        return data[train_indices], data[test_indices]  # Returns the training and test sets.\n",
        "\n",
        "    def euclidean_distance(self, instance1, instance2):\n",
        "        \"\"\"\n",
        "        Calculate the Euclidean distance between two instances.\n",
        "        Args:\n",
        "            instance1 (numpy array): The first instance.\n",
        "            instance2 (numpy array): The second instance.\n",
        "        Returns:\n",
        "            float: The Euclidean distance between the two instances.\n",
        "        \"\"\"\n",
        "        instance1_new = np.array(instance1[:-1])\n",
        "        instance2_new = np.array(instance2[:-1])\n",
        "        # The code creates new arrays from instance1 and instance2, excluding their last elements.\n",
        "\n",
        "        return np.sqrt(np.sum((instance1_new - instance2_new) ** 2))\n"
      ],
      "metadata": {
        "id": "HOwsZFalr8n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/iris.csv', sep=',', skiprows=0)\n",
        "data_array = data.to_numpy()\n",
        "\n",
        "# Create a KNN model with k=5 neighbors\n",
        "knn = KNN(k=5)\n",
        "\n",
        "# Seperating training data and testing data\n",
        "# 30% of the data is reserved for testing, 70% is reserved for training\n",
        "train_set, test_set = knn.train_test_split(data_array, test_size=0.3)\n",
        "\n",
        "# Separate features and labels\n",
        "# [:, :-1]  # All rows, all columns except the last\n",
        "# [:, -1]   # All rows, only the last column\n",
        "train_features, train_labels = train_set[:, :-1], train_set[:, -1]\n",
        "test_features, test_labels = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "# Train the model\n",
        "knn.fit(train_features, train_labels)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "predictions = knn.predict(test_features)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = np.mean(predictions == test_labels)\n",
        "# If the value is equal it gives 1, if not it gives 0. and creates an array from this data and takes the average of this array\n",
        "\n",
        "print(f'# Accuracy: {accuracy:.2f}', end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for training\n",
        "print(\"# Train Indices: \", np.sort(knn.train_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for testing\n",
        "print(\"# Test Indices: \", np.sort(knn.test_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Different predictions from the real ones in the test data\n",
        "print(\"# Different predictions from the real ones in the test data: \", end=\"\\n\")\n",
        "for i in range(test_features.shape[0]):\n",
        "    if(test_labels[i] != predictions[i]):\n",
        "        print(f'Indices: {knn.test_indices[i]}, Test Labels: {test_labels[i]}, Predictions: {predictions[i]}', end = \"\\n\")"
      ],
      "metadata": {
        "id": "6HRo7jQNtxfW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knnn = {}\n",
        "predictions = {}\n",
        "accuracy = {}\n",
        "\n",
        "for i in range(1, 149, 2):\n",
        "    knnn[i] = KNN(k=i)\n",
        "    knnn[i].fit(train_features, train_labels)\n",
        "    predictions[i] = knnn[i].predict(test_features)\n",
        "    accuracy[i] = np.mean(predictions[i] == test_labels)\n",
        "    print(f'# Accuracy for k = {i}: {accuracy[i]:.2f}')"
      ],
      "metadata": {
        "id": "9f03Dy73fdOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aFtvRoSP61IL"
      }
    }
  ]
}