{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhMaCgkEr+05w5mvKtWYwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enginpaksoy/ML/blob/main/KNN_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pkHFHHyKrivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/iris.csv', sep=',', skiprows=0)\n",
        "data_array = data.to_numpy()\n",
        "data_array2 = data_array"
      ],
      "metadata": {
        "id": "lyqn6bRkHk4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, data, k):\n",
        "        \"\"\"\n",
        "        Initialize the KNN class with k neighbors.\n",
        "        Args:\n",
        "            k (int): Number of nearest neighbors.\n",
        "        \"\"\"\n",
        "        self.data_size = data.shape[0]\n",
        "        self.k = k\n",
        "        if(k % 2 != 1):\n",
        "            raise ValueError(\"k must be an odd number\")\n",
        "\n",
        "    def fit(self, training_features, training_labels):\n",
        "        \"\"\"\n",
        "        Store the training data.\n",
        "        Args:\n",
        "            training_features (numpy array): Features of the training data.\n",
        "            training_labels (numpy array): Labels of the training data.\n",
        "        \"\"\"\n",
        "        self.training_features = training_features\n",
        "        self.training_labels = training_labels\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, test_features):\n",
        "        \"\"\"\n",
        "        Predict the labels for the test data.\n",
        "        Args:\n",
        "            test_features (numpy array): Features of the test data.\n",
        "        Returns:\n",
        "            numpy array: Predicted labels for the test data.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for test_instance in test_features:\n",
        "            distances = []\n",
        "            # Calculate distance from the test instance to all training instances\n",
        "            for training_instance in self.training_features:\n",
        "                distances.append(self.euclidean_distance(test_instance, training_instance))\n",
        "\n",
        "            # Find the k nearest neighbors\n",
        "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
        "            # records the indices with the lowest distance between them\n",
        "\n",
        "            nearest_labels = [self.training_labels[i] for i in nearest_neighbors]\n",
        "            # nearest_neighbors contains indices of the nearest neighbors\n",
        "            # Create a list of labels for these nearest neighbors by looking up the indices in self.training_labels\n",
        "\n",
        "            # Determine the most common label (voting)\n",
        "            predicted_label = max(set(nearest_labels), key=nearest_labels.count)\n",
        "            predictions.append(predicted_label)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "\n",
        "    def euclidean_distance(self, instance1, instance2):\n",
        "        \"\"\"\n",
        "        Calculate the Euclidean distance between two instances.\n",
        "        Args:\n",
        "            instance1 (numpy array): The first instance.\n",
        "            instance2 (numpy array): The second instance.\n",
        "        Returns:\n",
        "            float: The Euclidean distance between the two instances.\n",
        "        \"\"\"\n",
        "        instance1_new = np.array(instance1[:-1])\n",
        "        instance2_new = np.array(instance2[:-1])\n",
        "        # The code creates new arrays from instance1 and instance2, excluding their last elements.\n",
        "\n",
        "        return np.sqrt(np.sum((instance1_new - instance2_new) ** 2))\n"
      ],
      "metadata": {
        "id": "HOwsZFalr8n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN_without_kFold(KNN):\n",
        "    def __init__(self, data, k):\n",
        "        super().__init__(data, k)\n",
        "\n",
        "    def train_test_split(self, data, test_size=0.3):\n",
        "        \"\"\"\n",
        "        Split the data into training and test sets.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "            test_size (float): Size of the test set.\n",
        "        Returns:\n",
        "            tuple: Training and test sets.\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]  # Gets the number of samples in the data array.\n",
        "        num_test_samples = int(num_samples * test_size)  # Determines the size of the test set.\n",
        "        indices = np.random.permutation(num_samples)  # Creates an array of length num_samples and randomizes the elements of this array.\n",
        "        test_indices = indices[:num_test_samples]  # Takes the first n(length num_samples) indices for the test set.\n",
        "        train_indices = indices[num_test_samples:]  # Takes the remaining indices for the training set.\n",
        "\n",
        "        self.test_indices = test_indices\n",
        "        self.train_indices = train_indices\n",
        "\n",
        "        return data[train_indices], data[test_indices]  # Returns the training and test sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "dHBPbWsjH1Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN_with_KFold(KNN):\n",
        "    def __init__(self, data, k, kFold):\n",
        "        super().__init__(data, k)\n",
        "        self.kFold = kFold\n",
        "\n",
        "    def train_test_split(self, data, fold):\n",
        "        \"\"\"\n",
        "        Split the data into training and test sets.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]  # Gets the number of samples in the data array.\n",
        "        fold_size = num_samples // self.kFold  # Determines the size of each fold.\n",
        "        remainder = num_samples % self.kFold  # Calculates the remainder to handle non-even splits\n",
        "\n",
        "        # Determine the start and end indices of the test fold\n",
        "        test_start_idx = fold * fold_size + min(fold, remainder)\n",
        "        test_end_idx = test_start_idx + fold_size + (1 if fold < remainder else 0)\n",
        "\n",
        "        test_indices = np.arange(test_start_idx, test_end_idx)\n",
        "        train_indices = np.concatenate((np.arange(0, test_start_idx), np.arange(test_end_idx, num_samples)))\n",
        "        #print(test_indices)\n",
        "        self.train_features, self.train_labels = data[train_indices, :-1], data[train_indices, -1]\n",
        "        self.test_features, self.test_labels = data[test_indices, :-1], data[test_indices, -1]\n",
        "        #print(self.test_labels)\n",
        "\n",
        "\n",
        "\n",
        "    def cross_validation(self, data):\n",
        "        \"\"\"\n",
        "        Perform k-fold cross validation.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "            k-fold (int): Number of folds.\n",
        "        \"\"\"\n",
        "        predictions_list = []\n",
        "\n",
        "        for fold in range(self.kFold):\n",
        "            self.train_test_split(data_array, fold)\n",
        "            #self.seperate_features_labels(self.train_features, self.test_features)\n",
        "            self.fit(self.train_features, self.train_labels)\n",
        "            fold_predictions = self.predict(self.test_features)\n",
        "            predictions_list.extend(fold_predictions)  # Collect predictions from all folds\n",
        "\n",
        "\n",
        "        predictions_list_array = np.array(predictions_list)\n",
        "        all_real_labels = data_array[:, -1]\n",
        "        accuracy = np.mean(predictions_list_array == all_real_labels)\n",
        "\n",
        "        self.predicted_label = predictions_list_array\n",
        "        self.accuracy = accuracy"
      ],
      "metadata": {
        "id": "O7F18YxTHGWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### PREDICTING WITHOUT K-FOLDS METHOD ####\n",
        "# Create a KNN model with k=5 neighbors\n",
        "knn = KNN_without_kFold(data_array, k=5)\n",
        "\n",
        "# Seperating training data and testing data\n",
        "# 30% of the data is reserved for testing, 70% is reserved for training\n",
        "train_set, test_set = knn.train_test_split(data_array, test_size=0.3)\n",
        "\n",
        "# Separate features and labels\n",
        "# Use after deciding which ones goes to test, which ones goes to training\n",
        "# [:, :-1]  # All rows, all columns except the last\n",
        "# [:, -1]   # All rows, only the last column\n",
        "train_features, train_labels = train_set[:, :-1], train_set[:, -1]\n",
        "test_features, test_labels = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "# Train the model\n",
        "knn.fit(train_features, train_labels)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "predictions = knn.predict(test_features)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = np.mean(predictions == test_labels)\n",
        "# If the value is equal it gives 1, if not it gives 0. and creates an array from this data and takes the average of this array\n",
        "\n",
        "print(f'# Accuracy: {accuracy:.2f}', end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for training\n",
        "print(\"# Train Indices: #\", train_features.shape[0])\n",
        "print(np.sort(knn.train_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for testing\n",
        "print(\"# Test Indices: #\", test_features.shape[0])\n",
        "print(np.sort(knn.test_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Different predictions from the real ones in the test data\n",
        "print(\"# Different predictions from the real ones in the test data: \", end=\"\\n\")\n",
        "for i in range(test_features.shape[0]):\n",
        "    if(test_labels[i] != predictions[i]):\n",
        "        print(f'Indices: {knn.test_indices[i]}, Test Labels: {test_labels[i]}, Predictions: {predictions[i]}', end = \"\\n\")"
      ],
      "metadata": {
        "id": "OzOPquqxj710"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### PREDICTING WITH K-FOLDS METHOD ####\n",
        "knnn = []\n",
        "predictions = []\n",
        "accuracy = []\n",
        "best_k, max_accuracy = 0, 0\n",
        "best_index = 0\n",
        "\n",
        "# Train the model for different values of k\n",
        "for i in range(1, 151, 2):\n",
        "    model = KNN_with_KFold(data_array, k=i, kFold=4)  # Create the model instance\n",
        "    model.cross_validation(data_array)   # Perform cross-validation\n",
        "    #print(model.accuracy)\n",
        "    accuracy.append(model.accuracy)\n",
        "    knnn.append(model)  # Append the model to the list\n",
        "    if(model.accuracy > max_accuracy):\n",
        "        best_k = i\n",
        "        best_index = int((i - 1)/2)\n",
        "        max_accuracy = model.accuracy\n",
        "\n",
        "\n",
        "# Print the accuracy of the best model and the next 2 indices following it\n",
        "for i in range(best_k, best_k + 5, 2):\n",
        "    index = (i - 1) // 2  # Calculate the index for accuracy list\n",
        "    print(f\"# Accuracy for k = {i}: {accuracy[index]:.4f}\", end='')\n",
        "    if best_k == i:\n",
        "        print(' # BEST #', end='')\n",
        "    print()"
      ],
      "metadata": {
        "id": "6HRo7jQNtxfW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_3_models = []\n",
        "\n",
        "for i in range(3):\n",
        "    best_3_models.append(knnn[int(best_index) + i])\n",
        "\n",
        "def print_matching_columns(best_3_models, data_size):\n",
        "    all_real_labels = data_array[:, -1]\n",
        "    for i in range(data_size):\n",
        "        count = 0\n",
        "        for j in range(3):\n",
        "            if np.char.equal(best_3_models[j].predicted_label[i], all_real_labels[i]):\n",
        "                count += 1\n",
        "\n",
        "        if count <= 2:\n",
        "            print(f\"{best_3_models[0].predicted_label[i]:>19}\", end=\" \")\n",
        "            print(f\"{best_3_models[1].predicted_label[i]:>19}\", end=\" \")\n",
        "            print(f\"{best_3_models[2].predicted_label[i]:>19}\", end=\" \")\n",
        "            print(f\" {all_real_labels[i]:>19}\", end=\" \")\n",
        "            if count == 2:\n",
        "                print(f\"{'Consistently correct':>25}\", end=\" \")\n",
        "            if count == 1:\n",
        "                print(f\"{'Consistently incorrect':>25}\", end=\" \")\n",
        "            if count == 0:\n",
        "                print(f\"{'Inconsistent':>25}\", end=\" \")\n",
        "            print(f\" {i:>6}\", end=\"\\n\")\n"
      ],
      "metadata": {
        "id": "lzvQADyNpKWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"          KNN-{best_k}               KNN-{best_k+2}              KNN-{best_k+4}              REAL-LABEL            STATUS             INDEX()\")\n",
        "print_matching_columns(best_3_models, best_3_models[0].data_size)"
      ],
      "metadata": {
        "id": "RQHZE8Bw38hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aFtvRoSP61IL"
      }
    }
  ]
}