{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvxksz6MaS/BaaIA68r6L7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enginpaksoy/ML/blob/main/KNN2%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pkHFHHyKrivJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k):\n",
        "        \"\"\"\n",
        "        Initialize the KNN class with k neighbors.\n",
        "        Args:\n",
        "            k (int): Number of nearest neighbors.\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        if(k % 2 != 1):\n",
        "            raise ValueError(\"k must be an odd number\")\n",
        "\n",
        "    def fit(self, training_features, training_labels):\n",
        "        \"\"\"\n",
        "        Store the training data.\n",
        "        Args:\n",
        "            training_features (numpy array): Features of the training data.\n",
        "            training_labels (numpy array): Labels of the training data.\n",
        "        \"\"\"\n",
        "        self.training_features = training_features\n",
        "        self.training_labels = training_labels\n",
        "\n",
        "    def predict(self, test_features):\n",
        "        \"\"\"\n",
        "        Predict the labels for the test data.\n",
        "        Args:\n",
        "            test_features (numpy array): Features of the test data.\n",
        "        Returns:\n",
        "            numpy array: Predicted labels for the test data.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for test_instance in test_features:\n",
        "            distances = []\n",
        "            # Calculate distance from the test instance to all training instances\n",
        "            for training_instance in self.training_features:\n",
        "                distances.append(self.euclidean_distance(test_instance, training_instance))\n",
        "\n",
        "            # Find the k nearest neighbors\n",
        "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
        "            # records the indices with the lowest distance between them\n",
        "\n",
        "            nearest_labels = [self.training_labels[i] for i in nearest_neighbors]\n",
        "            # nearest_neighbors contains indices of the nearest neighbors\n",
        "            # Create a list of labels for these nearest neighbors by looking up the indices in self.training_labels\n",
        "\n",
        "            # Determine the most common label (voting)\n",
        "            predicted_label = max(set(nearest_labels), key=nearest_labels.count)\n",
        "            predictions.append(predicted_label)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def train_test_split(self, data, test_size=0.3):\n",
        "        \"\"\"\n",
        "        Split the data into training and test sets.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "            test_size (float): Size of the test set.\n",
        "        Returns:\n",
        "            tuple: Training and test sets.\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]  # Gets the number of samples in the data array.\n",
        "        num_test_samples = int(num_samples * test_size)  # Determines the size of the test set.\n",
        "        indices = np.random.permutation(num_samples)  # Creates an array of length num_samples and randomizes the elements of this array.\n",
        "        test_indices = indices[:num_test_samples]  # Takes the first n(length num_samples) indices for the test set.\n",
        "        train_indices = indices[num_test_samples:]  # Takes the remaining indices for the training set.\n",
        "        self.test_indices = test_indices\n",
        "        self.train_indices = train_indices\n",
        "        return data[train_indices], data[test_indices]  # Returns the training and test sets.\n",
        "\n",
        "    def kFold_cross_validation(self, data, kFold):\n",
        "        \"\"\"\n",
        "        Perform k-fold cross validation.\n",
        "        Args:\n",
        "            data (numpy array): Data to be split.\n",
        "            k-fold (int): Number of folds.\n",
        "        Returns:\n",
        "            tuple: Training and test sets.\n",
        "        \"\"\"\n",
        "        num_samples = data.shape[0]  # Gets the number of samples in the data array.\n",
        "        fold_size = int(num_samples // k)  # Determines the size of each fold.\n",
        "        accuracy_scores = []\n",
        "\n",
        "        for fold in range(k):\n",
        "            test_indices = np.arange(fold * fold_size, (fold + 1) * fold_size)  # Creates an array of indices for the test set.\n",
        "            train_indices = np.concatenate((np.arange(0, fold * fold_size), np.arange((fold + 1) * fold_size, len(data))))  # Creates an array of indices for the training set.\n",
        "            train_features, train_labels = data[train_indices], labels[train_indices]\n",
        "            test_features, test_labels = data[test_indices], labels[test_indices]\n",
        "\n",
        "            self.fit(train_features, train_labels)\n",
        "            predictions = self.predict(test_features)\n",
        "            accuracy = np.mean(predictions == test_labels)\n",
        "            accuracy_scores.append(accuracy)\n",
        "\n",
        "        self.predictions = predictions\n",
        "\n",
        "        return np.mean(accuracy_scores), accuracy_scores\n",
        "\n",
        "    def euclidean_distance(self, instance1, instance2):\n",
        "        \"\"\"\n",
        "        Calculate the Euclidean distance between two instances.\n",
        "        Args:\n",
        "            instance1 (numpy array): The first instance.\n",
        "            instance2 (numpy array): The second instance.\n",
        "        Returns:\n",
        "            float: The Euclidean distance between the two instances.\n",
        "        \"\"\"\n",
        "        instance1_new = np.array(instance1[:-1])\n",
        "        instance2_new = np.array(instance2[:-1])\n",
        "        # The code creates new arrays from instance1 and instance2, excluding their last elements.\n",
        "\n",
        "        return np.sqrt(np.sum((instance1_new - instance2_new) ** 2))\n"
      ],
      "metadata": {
        "id": "HOwsZFalr8n6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/iris.csv', sep=',', skiprows=0)\n",
        "data_array = data.to_numpy()"
      ],
      "metadata": {
        "id": "SJ_bIm-Ej5z5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### PREDICTING WITHOUT K-FOLDS METHOD ####\n",
        "# Create a KNN model with k=5 neighbors\n",
        "knn = KNN(k=5)\n",
        "\n",
        "# Seperating training data and testing data\n",
        "# 30% of the data is reserved for testing, 70% is reserved for training\n",
        "train_set, test_set = knn.train_test_split(data_array, test_size=0.3)\n",
        "\n",
        "# Separate features and labels\n",
        "# [:, :-1]  # All rows, all columns except the last\n",
        "# [:, -1]   # All rows, only the last column\n",
        "train_features, train_labels = train_set[:, :-1], train_set[:, -1]\n",
        "test_features, test_labels = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "# Train the model\n",
        "knn.fit(train_features, train_labels)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "predictions = knn.predict(test_features)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = np.mean(predictions == test_labels)\n",
        "# If the value is equal it gives 1, if not it gives 0. and creates an array from this data and takes the average of this array\n",
        "\n",
        "print(f'# Accuracy: {accuracy:.2f}', end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for training\n",
        "print(\"# Train Indices: #\", train_features.shape[0])\n",
        "print(np.sort(knn.train_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Which indices are reserved for testing\n",
        "print(\"# Test Indices: #\", test_features.shape[0])\n",
        "print(np.sort(knn.test_indices), end = \"\\n\\n\")\n",
        "\n",
        "# Different predictions from the real ones in the test data\n",
        "print(\"# Different predictions from the real ones in the test data: \", end=\"\\n\")\n",
        "for i in range(test_features.shape[0]):\n",
        "    if(test_labels[i] != predictions[i]):\n",
        "        print(f'Indices: {knn.test_indices[i]}, Test Labels: {test_labels[i]}, Predictions: {predictions[i]}', end = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzOPquqxj710",
        "outputId": "89c2e215-e574-4c53-baac-b03e0c76a88e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Accuracy: 0.98\n",
            "\n",
            "# Train Indices: # 105\n",
            "[  0   1   2   3   4   5   9  11  15  16  17  18  19  20  22  24  27  28\n",
            "  29  30  31  32  34  36  37  41  42  43  44  46  47  48  49  51  53  54\n",
            "  56  57  58  59  61  64  65  67  68  69  70  73  76  77  78  79  80  81\n",
            "  82  83  84  87  90  91  92  93  94  95  96  97  99 100 101 104 105 106\n",
            " 107 108 111 112 113 114 115 116 117 119 120 121 123 124 125 126 127 128\n",
            " 130 131 133 134 135 137 138 139 140 142 143 144 145 147 148]\n",
            "\n",
            "# Test Indices: # 45\n",
            "[  6   7   8  10  12  13  14  21  23  25  26  33  35  38  39  40  45  50\n",
            "  52  55  60  62  63  66  71  72  74  75  85  86  88  89  98 102 103 109\n",
            " 110 118 122 129 132 136 141 146 149]\n",
            "\n",
            "# Different predictions from the real ones in the test data: \n",
            "Indices: 72, Test Labels: Iris-versicolor, Predictions: Iris-virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### PREDICTING WITH K-FOLDS METHOD ####\n"
      ],
      "metadata": {
        "id": "6HRo7jQNtxfW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knnn = {}\n",
        "predictions = {}\n",
        "accuracy = {}\n",
        "best_k, max_accuracy = 0, 0\n",
        "\n",
        "for i in range(1, 151, 2):\n",
        "    knnn[i] = KNN(k=i)\n",
        "    knnn[i].fit(train_features, train_labels)\n",
        "    predictions[i] = knnn[i].predict(test_features)\n",
        "    accuracy[i] = np.mean(predictions[i] == test_labels)\n",
        "\n",
        "    if(accuracy[i] > max_accuracy):\n",
        "        max_accuracy = accuracy[i]\n",
        "        best_k = i\n",
        "\n",
        "    print(f'# Accuracy for k = {i}: {accuracy[i]:.4f}')\n",
        "\n",
        "print(f'Best k: {best_k}, Max Accuracy: {max_accuracy:.2f}')"
      ],
      "metadata": {
        "id": "9f03Dy73fdOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e62b8d8-789e-4d53-edca-70360ec751b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Accuracy for k = 1: 0.9556\n",
            "# Accuracy for k = 3: 0.9778\n",
            "# Accuracy for k = 5: 0.9778\n",
            "# Accuracy for k = 7: 0.9556\n",
            "# Accuracy for k = 9: 0.9778\n",
            "# Accuracy for k = 11: 0.9778\n",
            "# Accuracy for k = 13: 0.9778\n",
            "# Accuracy for k = 15: 0.9333\n",
            "# Accuracy for k = 17: 0.9556\n",
            "# Accuracy for k = 19: 0.9333\n",
            "# Accuracy for k = 21: 0.9333\n",
            "# Accuracy for k = 23: 0.9333\n",
            "# Accuracy for k = 25: 0.9111\n",
            "# Accuracy for k = 27: 0.9111\n",
            "# Accuracy for k = 29: 0.9111\n",
            "# Accuracy for k = 31: 0.9111\n",
            "# Accuracy for k = 33: 0.9111\n",
            "# Accuracy for k = 35: 0.9111\n",
            "# Accuracy for k = 37: 0.9111\n",
            "# Accuracy for k = 39: 0.9111\n",
            "# Accuracy for k = 41: 0.9111\n",
            "# Accuracy for k = 43: 0.9111\n",
            "# Accuracy for k = 45: 0.9111\n",
            "# Accuracy for k = 47: 0.9111\n",
            "# Accuracy for k = 49: 0.8889\n",
            "# Accuracy for k = 51: 0.8889\n",
            "# Accuracy for k = 53: 0.8889\n",
            "# Accuracy for k = 55: 0.8889\n",
            "# Accuracy for k = 57: 0.8889\n",
            "# Accuracy for k = 59: 0.8889\n",
            "# Accuracy for k = 61: 0.8889\n",
            "# Accuracy for k = 63: 0.9111\n",
            "# Accuracy for k = 65: 0.8667\n",
            "# Accuracy for k = 67: 0.8667\n",
            "# Accuracy for k = 69: 0.7556\n",
            "# Accuracy for k = 71: 0.7778\n",
            "# Accuracy for k = 73: 0.7111\n",
            "# Accuracy for k = 75: 0.6889\n",
            "# Accuracy for k = 77: 0.3778\n",
            "# Accuracy for k = 79: 0.3556\n",
            "# Accuracy for k = 81: 0.3556\n",
            "# Accuracy for k = 83: 0.3556\n",
            "# Accuracy for k = 85: 0.3556\n",
            "# Accuracy for k = 87: 0.3556\n",
            "# Accuracy for k = 89: 0.3556\n",
            "# Accuracy for k = 91: 0.3556\n",
            "# Accuracy for k = 93: 0.3556\n",
            "# Accuracy for k = 95: 0.3556\n",
            "# Accuracy for k = 97: 0.3333\n",
            "# Accuracy for k = 99: 0.3333\n",
            "# Accuracy for k = 101: 0.3111\n",
            "# Accuracy for k = 103: 0.2667\n",
            "# Accuracy for k = 105: 0.2667\n",
            "# Accuracy for k = 107: 0.2667\n",
            "# Accuracy for k = 109: 0.2667\n",
            "# Accuracy for k = 111: 0.2667\n",
            "# Accuracy for k = 113: 0.2667\n",
            "# Accuracy for k = 115: 0.2667\n",
            "# Accuracy for k = 117: 0.2667\n",
            "# Accuracy for k = 119: 0.2667\n",
            "# Accuracy for k = 121: 0.2667\n",
            "# Accuracy for k = 123: 0.2667\n",
            "# Accuracy for k = 125: 0.2667\n",
            "# Accuracy for k = 127: 0.2667\n",
            "# Accuracy for k = 129: 0.2667\n",
            "# Accuracy for k = 131: 0.2667\n",
            "# Accuracy for k = 133: 0.2667\n",
            "# Accuracy for k = 135: 0.2667\n",
            "# Accuracy for k = 137: 0.2667\n",
            "# Accuracy for k = 139: 0.2667\n",
            "# Accuracy for k = 141: 0.2667\n",
            "# Accuracy for k = 143: 0.2667\n",
            "# Accuracy for k = 145: 0.2667\n",
            "# Accuracy for k = 147: 0.2667\n",
            "# Accuracy for k = 149: 0.2667\n",
            "Best k: 3, Max Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hT2yfMMCUcWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aFtvRoSP61IL"
      }
    }
  ]
}